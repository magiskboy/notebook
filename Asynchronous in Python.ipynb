{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coroutine in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "* Explore and compare the models programming for asynchronous problems\n",
    "* Asychronous, use cases and some approaches\n",
    "* What is the coroutines? How does it works? Comparations units of work\n",
    "* Application of coroutines in real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is asynchronous?\n",
    "\n",
    "Follow [Wikipedia](https://en.wikipedia.org/wiki/Asynchrony_(computer_programming)\n",
    "> Asynchrony, in computer programming, refers to the occurrence of events independent of the main program flow and ways to deal with such events. These may be \"outside\" events such as the arrival of signals, or actions instigated by a program that take place concurrently with program execution, without the program blocking to wait for results. Asynchronous input/output is an example of the latter cause of asynchrony, and lets programs issue commands to storage or network devices that service these requests while the processor continues executing the program. Doing so provides a degree of parallelism\n",
    "\n",
    "The under, we have some solutions for asynchronous tasks\n",
    "\n",
    "![Async models](./assets/images/async-overview.jpg)\n",
    "\n",
    "Notice, the python thread is the green thread, it is managed by interpreter instead of OS. Thus, python thread isn't really parallelism and I hate it.\n",
    "\n",
    "We can see that threads and processes owns isolated space memory thus they can independent work with the main process.\n",
    "\n",
    "Opposite, the event loop maintains tasks, which is shared memory and we must answer the question `How do we organize memory space for independent tasks?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When we use event loop, threads and processes?\n",
    "\n",
    "In computer science, we can classify two classes of task:\n",
    "* CPU bound\n",
    "    > In computer science, a computer is CPU-bound (or compute-bound) when the time for it to complete a task is determined principally by the speed of the central processor: processor utilization is high, perhaps at 100% usage for many seconds or minutes. Interrupts generated by peripherals may be processed slowly, or indefinitely delayed.\n",
    "    \n",
    "* I/O bound\n",
    "    > I/O bound refers to a condition in which the time it takes to complete a computation is determined principally by the period spent waiting for input/output operations to be completed. This is the opposite of a task being CPU bound. This circumstance arises when the rate at which data is requested is slower than the rate it is consumed or, in other words, more time is spent requesting data than processing it\n",
    "    \n",
    "**Example**:\n",
    "* using multiprocess (native thread) for I/O bound\n",
    "\n",
    "    Jason asks Dung that 'What do you do in today?' and Dung reponses that his tasks is pending in testing and he doesn't have task thus he will back to home and ðŸ˜´.\n",
    "    \n",
    "    No, it isn't optimization solution. Instead, Dung should do other tasks until Ms.Quyen said that 'Hey Dung, your tasks failed, fix it' ðŸ˜¥.\n",
    "    \n",
    "    Awesome, this is how event loop works for I/O bound tasks\n",
    "    \n",
    "* using event loop for CPU bound\n",
    "\n",
    "    Our team has 5 members and 5 tasks but only Dung takes all tasks then do. Because each task must be committed at the end of the day so Dung do each task for an hour and move on to another task. Thus Dung is sick in the weekend ðŸ˜·.\n",
    "    \n",
    "    No, we have 5 members and why do we push Dung? Jason can deal the tasks to other members and end of the day, all tasks are committed but Dung is ok.\n",
    "    \n",
    "    This is how multiprocessing (native threads) works.\n",
    "    \n",
    "    \n",
    "Really, event loop useful in the event system and related others. They can be best solution for I/O bound problems  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems of task in event loop model\n",
    "\n",
    "We known that we have a context in the function. The context includes variables, stack frame,... and they are unlocatted by interpreter after return command executed. \n",
    "\n",
    "In I/O problems, we usually have tasks, which consists of many small parts interrupted by commands delay for IO. At the interrupted point, we need return control for caller (event loop) of function (task) and we also need execute this function at the interrupt, which is return.\n",
    "\n",
    "==> Solution: coroutine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is coroutine?\n",
    "\n",
    "Donald Knuth says:\n",
    "> Subroutines are special cases of coroutine\n",
    "\n",
    "\n",
    "How coroutine works?\n",
    "\n",
    "![](assets/images/subroutine_coroutine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit of works\n",
    "\n",
    "|| Process | Native thread | Green thread | Goroutine | Coroutine |\n",
    "| :-:| :-: | :-: | :-: | :-:| :-: |\n",
    "|__Memory__| â‰¤ 8Mb | â‰¤ Nx2Mb | â‰¥ 64Kb | â‰¥ 8Kb | â‰¥ 0Mb |\n",
    "|__OS managed__| Yes | Yes | No | No | No |\n",
    "|__Pre-emptive scheduling__| Yes | Yes | Yes | No | No |\n",
    "|__Private address space__| Yes | No | No | No | No |\n",
    "|__Parallel__| Yes | Yes | No | Yes | No |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### How implement coroutine from scratch?\n",
    "\n",
    "```c\n",
    "#include <stdio.h>\n",
    "\n",
    "int coroutine() {\n",
    "    static int i = 0, s = 0;\n",
    "    switch (s) {\n",
    "        case 0:\n",
    "            for (i = 0;; ++i) {\n",
    "                if (!s) s = 1;\n",
    "                return i;\n",
    "                case 1:;\n",
    "            }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    printf(\"%d\\n\", coroutine());     // ?\n",
    "    printf(\"%d\\n\", coroutine());     // ?\n",
    "    printf(\"%d\\n\", coroutine());     // ?\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "We can see that coroutine need static memory namespace for save context when it suspends and resumes without lost context. In C, static namespace is static variables, they are maintained by OS when function done. In Python, context of function is stored in stack frame. \n",
    "\n",
    "__Summary__ the coroutine has some features:\n",
    "* is non preemptive scheduling\n",
    "* can suspend and resume at the anywhere\n",
    "* can maintain state\n",
    "* for I/O bound, coroutine optimize memory and CPU\n",
    "\n",
    "Coroutine increases many bugs of multiprocessing and I think it is best solution for networking tasks because it alive in single process.\n",
    "\n",
    "In Python, we can define coroutine by use `yield` statement in the function. When we call functions, they return coroutine object instead of final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coro_fn():\n",
    "    val = yield 'Starting'   # started coroutine and suspend, return control to caller\n",
    "    print('Consume', val)\n",
    "    yield 'Hello World'      # produce data\n",
    "    \n",
    "co = coro_fn()               # create a new coroutine object\n",
    "print(co.send(None))         # start coroutine\n",
    "print(co.send('data'))       # resume coroutine, pass control into coroutine\n",
    "co.close()                   # close coroutine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator is the specical coroutine, they can only produce data without consume data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_gen():\n",
    "    a, b = 0, 1           # this is maintained context\n",
    "    while 1:\n",
    "        yield a           # return control to for loop\n",
    "        a, b = b, a + b\n",
    "        \n",
    "fib = fib_gen()\n",
    "for _ in range(10):\n",
    "    print(next(fib), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of coroutine\n",
    "\n",
    "\n",
    "#### 1. Asychronous TCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sys import stdout\n",
    "from socket import socket, SOCK_STREAM, AF_INET\n",
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=stdout, level=logging.DEBUG)\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, host, port, buf_size=64):\n",
    "        self.addr = (host, port)\n",
    "        self.poll = DefaultSelector()\n",
    "        self.m = {}\n",
    "        self.buf_size = buf_size\n",
    "\n",
    "    def handle_read(self, sock):  # make isolated environment for each connection\n",
    "        buffer_size = self.buf_size\n",
    "        handle_write = self.handle_write\n",
    "\n",
    "        def _can_read():\n",
    "            chunks = []\n",
    "            while 1:\n",
    "                chunk = sock.recv(buffer_size)\n",
    "                if chunk.endswith(b'\\n\\n'):\n",
    "                    chunks.append(chunk[:-2])\n",
    "                    break\n",
    "                else:\n",
    "                    chunks.append(chunk)\n",
    "                    yield\n",
    "\n",
    "            handle_write(sock, b''.join(chunks))\n",
    "\n",
    "        handler = _can_read()\n",
    "        self.m[sock] = handler\n",
    "        self.poll.register(sock, EVENT_READ, handler)\n",
    "\n",
    "    def handle_write(self, sock, data):     # make isolated environment for each connection\n",
    "        poll = self.poll\n",
    "        m = self.m\n",
    "        buffer_size = self.buf_size\n",
    "\n",
    "        def _can_write():\n",
    "            nonlocal data, sock\n",
    "            start_, end_ = 0, 0\n",
    "            data = b'Hello ' + data\n",
    "            len_data = len(data)\n",
    "\n",
    "            while 1:\n",
    "                end_ = min(start_ + buffer_size, len_data)\n",
    "                if start_ >= end_:\n",
    "                    break\n",
    "                sock.send(data[start_:end_])\n",
    "                start_ += buffer_size\n",
    "                yield\n",
    "\n",
    "            # clear handler of connection and close conection\n",
    "            poll.unregister(sock)\n",
    "            del m[sock]\n",
    "            sock.close()\n",
    "            del sock\n",
    "\n",
    "        handler = _can_write()\n",
    "        m[sock] = handler\n",
    "        poll.modify(sock, EVENT_WRITE, handler)\n",
    "\n",
    "    def handle_accept(self, sock):\n",
    "        while 1:\n",
    "            s, addr = sock.accept()\n",
    "            logging.debug(f'Accept the connection from {addr}')\n",
    "            self.handle_read(s)\n",
    "            yield\n",
    "\n",
    "    def mainloop(self):\n",
    "        try:\n",
    "            sock = socket(AF_INET, SOCK_STREAM)\n",
    "            sock.bind(self.addr)\n",
    "            sock.setblocking(0)\n",
    "            sock.listen(1024)\n",
    "\n",
    "            self.m[sock] = self.handle_accept(sock)\n",
    "            self.poll.register(sock, EVENT_READ, self.m[sock])\n",
    "\n",
    "            logging.info(f'Server is running at {self.addr}')\n",
    "            while 1:\n",
    "                events = self.poll.select()\n",
    "                for event, _ in events:\n",
    "                    try:\n",
    "                        cb = event.data\n",
    "                        next(cb)\n",
    "                    except StopIteration:\n",
    "                        pass\n",
    "        except Exception as e:\n",
    "            sock.close()\n",
    "            self.poll.close()\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server('127.0.0.1', 5000)\n",
    "server.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scheduler for OS\n",
    "\n",
    "![](./assets/images/os-scheduler.png)\n",
    "\n",
    "When statement hits a trap, program passes control to OS and OS executes the statements or switch other tasks and passes control to it.\n",
    "\n",
    "But this model is non preemptive scheduler, I give you this model for explain relationship between `yield` expression and `trap` in OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "\n",
    "class SystemCall:\n",
    "    __slots__ = ('sched', 'target')\n",
    "\n",
    "    def handle(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Task:\n",
    "    __slots__ = ('id', 'target', 'sendval')\n",
    "    _id = 0\n",
    "\n",
    "    def __init__(self, target):\n",
    "        Task._id += 1\n",
    "        self.id = Task._id\n",
    "        self.target = target\n",
    "        self.sendval = None\n",
    "\n",
    "    def run(self):\n",
    "        return self.target.send(self.sendval)\n",
    "\n",
    "\n",
    "class Scheduler:\n",
    "    __slots__ = ('taskmap', 'ready')\n",
    "\n",
    "    def __init__(self):\n",
    "        self.taskmap = {}\n",
    "        self.ready = Queue()\n",
    "\n",
    "    def new(self, target):\n",
    "        task = Task(target)\n",
    "        self.taskmap[task.id] = task\n",
    "        self.schedule(task)\n",
    "        return task.id\n",
    "\n",
    "    def mainloop(self):\n",
    "        while self.taskmap:\n",
    "            task = self.ready.get()\n",
    "            try:\n",
    "                result = task.run()\n",
    "                if isinstance(result, SystemCall):\n",
    "                    result.task = task\n",
    "                    result.sched = self\n",
    "                    result.handle()\n",
    "                    continue\n",
    "            except StopIteration:\n",
    "                self.exit(task)\n",
    "            else:\n",
    "                self.schedule(task)\n",
    "\n",
    "    def schedule(self, task):\n",
    "        self.ready.put(task)\n",
    "\n",
    "    def exit(self, task):\n",
    "        print('Task %d terminated' % task.id)\n",
    "        del self.taskmap[task.id]\n",
    "\n",
    "\n",
    "class GetTid(SystemCall):\n",
    "    def handle(self):\n",
    "        self.task.sendval = self.task.id\n",
    "        self.sched.schedule(self.task)\n",
    "\n",
    "\n",
    "class NewTask(SystemCall):\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "\n",
    "    def handle(self):\n",
    "        tid = self.sched.new(self.target)\n",
    "        self.task.sendval = tid\n",
    "        self.sched.schedule(self.task)\n",
    "\n",
    "\n",
    "class KillTask(SystemCall):\n",
    "    def __init__(self, tid):\n",
    "        self.tid = tid\n",
    "\n",
    "    def handle(self):\n",
    "        task = self.sched.taskmap.get(self.tid, None)\n",
    "        if task:\n",
    "            task.target.close()\n",
    "            self.task.sendval = True\n",
    "        else:\n",
    "            self.task.sendval = False\n",
    "        self.sched.schedule(self.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    tid = yield GetTid()\n",
    "    print(f'I\\'m foo and I am living in {tid} process')\n",
    "    for i in range(5):\n",
    "        print(f\"Foo {tid} is in {i} step\")\n",
    "        yield\n",
    "\n",
    "def bar():\n",
    "    tid = yield GetTid()\n",
    "    print(f\"I'm bar and I'm living in {tid} process\")\n",
    "    yield NewTask(foo())\n",
    "    for i in range(3):\n",
    "        print(f\"Bar {tid} is in {i} step\")\n",
    "        yield\n",
    "    yield KillTask(1)\n",
    "\n",
    "sched = Scheduler()\n",
    "sched.new(foo())\n",
    "sched.new(bar())\n",
    "sched.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Streamming system\n",
    "\n",
    "\n",
    "We can use coroutines build up data processing system. Basically, the system was separate to logic blocks. They put in coroutines with owned context. You can see under picture.\n",
    "\n",
    "![](assets/images/simple-data-processing.png)\n",
    "\n",
    "We can describe many kind of systems if we create specify logic block: filter, conditional, selector, broadcast,...\n",
    "\n",
    "Example: build statistic IP from access log in the web server\n",
    "\n",
    "![](assets/images/IP-statistic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coroutine(f):\n",
    "    def decorator(*args, **kwargs):\n",
    "        co = f(*args, **kwargs)\n",
    "        co.send(None)   # start coroutine before use it\n",
    "        return co\n",
    "    return decorator\n",
    " \n",
    "@coroutine\n",
    "def broadcast(targets):\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            for target in targets:\n",
    "                target.send(data)\n",
    "    except GeneratorExit:\n",
    "        for target in targets:\n",
    "            target.close()\n",
    "            \n",
    "@coroutine\n",
    "def map_(ip, next_):\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            if data.startswith(ip):\n",
    "                next_.send(ip)\n",
    "    except GeneratorExit:\n",
    "        next_.close()\n",
    "        \n",
    "@coroutine\n",
    "def reduce_(on_done):\n",
    "    m = {}\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            if data not in m:\n",
    "                m[data] = 1\n",
    "            else:\n",
    "                m[data] += 1\n",
    "    except GeneratorExit:\n",
    "        on_done(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}\n",
    "def on_done(r):\n",
    "    global result\n",
    "    result = r\n",
    "\n",
    "reducer = reduce_(on_done)\n",
    "flow = broadcast([\n",
    "    map_('83.149.9.216', reducer),\n",
    "    map_('93.114.45.13', reducer),\n",
    "    map_('207.241.237.101', reducer),\n",
    "])\n",
    "\n",
    "# this is the source data\n",
    "# We have 10000 lines in this log\n",
    "%time\n",
    "with open('assets/files/access.log', 'r') as fp:\n",
    "    for line in fp.readlines():\n",
    "        flow.send(line)\n",
    "    flow.close()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement\n",
    "\n",
    "We can wrapper threads (or process or machine) in coroutines, Why not?\n",
    "\n",
    "Simiplify, I use threads instead of machine\n",
    "\n",
    "OK, let's redesign above diagram\n",
    "\n",
    "![](assets/images/IP-Statistic-v2.png)\n",
    "\n",
    "In above diagram, I move logic into threads and I use queues as a communication channels with threads.\n",
    "\n",
    "Furthermore, queues is used as buffer if rate of input is greater than rate of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "def coroutine(f):\n",
    "    def decorator(*args, **kwargs):\n",
    "        co = f(*args, **kwargs)\n",
    "        co.send(None)\n",
    "        return co\n",
    "    return decorator\n",
    " \n",
    "@coroutine\n",
    "def broadcast_threaded(targets):\n",
    "    queue = Queue()\n",
    "    def _run_target():\n",
    "        nonlocal queue, targets\n",
    "        while 1:\n",
    "            data = queue.get()\n",
    "            if data is GeneratorExit:\n",
    "                for target in targets:\n",
    "                    target.close()\n",
    "                return\n",
    "            else:\n",
    "                for target in targets:\n",
    "                    target.send(data)\n",
    "    Thread(target=_run_target).run()\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            queue.put(data)\n",
    "    except GeneratorExit:\n",
    "        queue.put(GeneratorExit)\n",
    "            \n",
    "@coroutine\n",
    "def map_threaded(ip, next_):\n",
    "    queue = Queue()\n",
    "    def _run_target():\n",
    "        nonlocal ip, queue\n",
    "        while 1:\n",
    "            data = queue.get()\n",
    "            if data is GeneratorExit:\n",
    "                next_.close()\n",
    "                return\n",
    "            else:\n",
    "                if data.startswith(ip):\n",
    "                    next_.send(ip)\n",
    "    Thread(target=_run_target).run()\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            queue.put(data)\n",
    "    except GeneratorExit:\n",
    "        queue.put(GeneratorExit)\n",
    "        \n",
    "@coroutine\n",
    "def reduce_threaded(on_done):\n",
    "    m = {}\n",
    "    queue = Queue()\n",
    "    def _run_target():\n",
    "        nonlocal queue, m, on_done\n",
    "        while 1:\n",
    "            data = queue.get()\n",
    "            if data is GeneratorExit:\n",
    "                on_done(m)\n",
    "                return\n",
    "            else:\n",
    "                if data not in m:\n",
    "                    m[data] = 1\n",
    "                else:\n",
    "                    m[data] += 1\n",
    "    t = Thread(target=_run_target)\n",
    "    t.run()\n",
    "    try:\n",
    "        while 1:\n",
    "            data = yield\n",
    "            queue.put(data)\n",
    "    except GeneratorExit:\n",
    "        queue.put(GeneratorExit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
